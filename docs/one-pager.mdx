---
title: dupcanon one-pager
description: Problem, approach, safety model, and current status.
---

<Info>
`dupcanon` is currently human-operated, but it is being shaped for workflow-native automation in GitHub Actions.
</Info>

## What this is

<CardGroup cols={2}>
  <Card title="Primary objective">
    Reduce duplicate noise in high-cadence repos (for example, OpenClaw) by selecting stable canonicals and closing true duplicates safely.
  </Card>
  <Card title="Why it exists">
    Naive automation creates duplicate chains and unstable targets; this system adds durable state + deterministic gates.
  </Card>
  <Card title="Operating constraints">
    Cheap enough to run continuously, accurate enough for guarded production use, and fully auditable.
  </Card>
  <Card title="Core strategy">
    Embeddings for retrieval, LLM for semantic judgment, deterministic policy for acceptance and close safety.
  </Card>
</CardGroup>

## Current vs target mode

<Tabs>
  <Tab title="Current mode">
    - Human-operated CLI pipeline
    - Online `detect-new` in shadow/suggest mode
    - Close actions gated through reviewed `plan-close` + explicit `apply-close --yes`
  </Tab>
  <Tab title="Target mode">
    - Workflow-driven automation in GitHub Actions
    - `detect-new` as the online entrypoint for new issues/PRs
    - Same deterministic guardrails, with policy-based promotion from shadow to action
  </Tab>
</Tabs>

## Core approach

Two paths share one data model and one safety model.

1. **Online entrypoint:** `detect-new` for newly opened issues/PRs
2. `sync` / `refresh`: ingest issues + PRs into Postgres
3. `embed`: title/body embeddings in pgvector
4. `candidates`: persisted nearest-neighbor candidate sets
5. `judge`: LLM chooses duplicate target inside the candidate set
6. deterministic gates veto risky decisions
7. `canonicalize`: compute canonical representatives
8. `plan-close` -> reviewed `apply-close --yes`

<Note>
All key artifacts are persisted for replay, audit, and threshold tuning.
</Note>

## Deterministic gates (high level)

<AccordionGroup>
  <Accordion title="Judge acceptance gates">
    - strict JSON parse
    - target must be in candidate set
    - confidence threshold (`>= 0.85`)
    - target must be open
    - selected candidate score gap vs best alternate (`>= 0.015`)
    - mismatch vetoes (uncertain/overlap/root-cause/scope class failures)
    - one accepted outgoing edge per source unless explicit rejudge
  </Accordion>
  <Accordion title="Close planning gates">
    - maintainer author protection
    - maintainer assignee protection
    - direct accepted edge to canonical required
    - higher close threshold (`>= 0.90`)
  </Accordion>
</AccordionGroup>

## Cost and accuracy stance

<Tip>
Goal is practical operations, not perfect AI: keep cost low enough for continuous runs, keep precision high enough for controlled close actions.
</Tip>

## Current status

Implemented commands:

- `init`, `sync`, `refresh`, `embed`, `candidates`, `judge`
- `judge-audit`, `report-audit`, `detect-new`
- `canonicalize`, `maintainers`, `plan-close`, `apply-close`

## Whatâ€™s missing next

- first-class evaluation command + reporting workflow for production gate decisions
- programmatic orchestration command/workflow for unattended DB freshness updates
- richer action surface in future (for example, label taxonomy / tree-editing operations)

## Stack

- Python + Typer + Pydantic + Rich
- Supabase Postgres + pgvector
- providers: OpenAI, Gemini, OpenRouter, and `openai-codex` via `pi` RPC

DB can be moved to self-hosted Postgres with minimal architecture changes.

## Internal docs

Deep design and runbook docs are in `docs/internal/`.
